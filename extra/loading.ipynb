{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427f0300-2c64-4554-9dd0-4c0805213126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total judgments in metadata: 15609103\n",
      "Courts available: ['Bombay High Court' 'Calcutta High Court' 'High Court of Meghalaya'\n",
      " 'High Court of Jammu and Kashmir' 'High Court of Uttarakhand'\n",
      " 'High Court of Punjab and Haryana' 'High Court of Madhya Pradesh'\n",
      " 'Madras High Court' 'High Court for State of Telangana'\n",
      " 'Patna High Court' 'Allahabad High Court' 'High Court of Kerala'\n",
      " 'High Court of Gujarat' 'High Court of Andhra Pradesh'\n",
      " 'High Court of Orissa' 'Gauhati High Court' 'High Court of Chhattisgarh'\n",
      " 'High Court of Himachal Pradesh' 'High Court of Tripura'\n",
      " 'High Court of Delhi' 'High Court of Jharkhand' 'High Court of Manipur'\n",
      " 'High Court of Sikkim' 'High Court of Karnataka'\n",
      " 'High Court of Rajasthan']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Path where metadata is stored\n",
    "metadata_dir = os.path.expanduser(\"~/high_court_dataset/metadata\")\n",
    "\n",
    "# Collect all metadata records\n",
    "records = []\n",
    "for root, _, files in os.walk(metadata_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".json\"):\n",
    "            with open(os.path.join(root, f), \"r\") as infile:\n",
    "                try:\n",
    "                    data = json.load(infile)\n",
    "                    records.append(data)\n",
    "                except:\n",
    "                    pass  # skip broken json\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(\"Total judgments in metadata:\", len(df))\n",
    "print(\"Courts available:\", df[\"court_name\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5e6bc7-798a-49be-a6c8-11fa55bfa31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled judgments: 52000\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataframe\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Target: 50k total\n",
    "target_total = 52000\n",
    "courts = df[\"court_name\"].unique()\n",
    "per_court = target_total // len(courts)\n",
    "\n",
    "sampled = df.groupby(\"court_name\").head(per_court)\n",
    "print(\"Sampled judgments:\", len(sampled))\n",
    "\n",
    "# Save list of keys (paths in S3) for downloading\n",
    "sampled.to_csv(\"sampled_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903fa4c8-b47b-40d1-abb2-4c583efd9c19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚úÖ Total judgments in metadata: 15609102\n",
      "==================================================\n",
      "üìÇ Columns in DataFrame: ['court_code', 'court_name', 'raw_html', 'pdf_link', 'downloaded']\n",
      "==================================================\n",
      "üîç Sample record:\n",
      "[{'court_code': '27~1', 'court_name': 'Bombay High Court', 'raw_html': '<button type=\\'button\\' role=\\'link\\' class=\\'btn btn-link p-0 text-start\\' id=\\'link_0\\' aria-label=\"INPT/49/1969 of SETH RAMCHAND SHAMDAS .Array[93]. S.D. TALREJA pdf\"  class=\\'noToken\\' href=\\'#\\' onclick=javascript:open_pdf(\\'0\\',\\'\\',\\'court/cnrorders/newos/orders/HCBM020000311969_1_2006-12-22.pdf#page=&search=%20\\'); ><font size=\\'3\\'>INPT/49/1969 of SETH RAMCHAND SHAMDAS Vs S.D. TALREJA</button></font><br><strong>Judge : RETIRED JUDGE</strong><br> THE HIGH COURT OF JUDICATURE AT BOMBAY THE HIGH COURT OF JUDICATURE<br><strong class=\\'caseDetailsTD\\' ><span style=\\'color:#212F3D\\'> CNR :</span><font color=\\'green\\'> HCBM020000311969</font><span style=\\'color:#212F3D\\' > | Date of registration :</span><font color=\\'green\\'> 21-12-2006</font><span style=\\'color:#212F3D\\' > | Decision Date :</span><font color=\\'green\\'> 15-07-1969</font><span style=\\'color:#212F3D\\' > | Disposal Nature :</span><font color=\\'green\\'> DISPOSED OFF</font><br><span style=\\'opacity: 0.5;\\'>Court : Bombay High Court</span></strong>', 'pdf_link': 'court/cnrorders/newos/orders/HCBM020000311969_1_2006-12-22.pdf', 'downloaded': True}]\n",
      "==================================================\n",
      "‚ö†Ô∏è 'court' column not found.\n",
      "üëâ Available columns you can try instead: ['court_code', 'court_name', 'raw_html', 'pdf_link', 'downloaded']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path where metadata is stored\n",
    "metadata_dir = os.path.expanduser(\"~/high_court_dataset/metadata\")\n",
    "\n",
    "# Collect all metadata records\n",
    "records = []\n",
    "for root, _, files in os.walk(metadata_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, f)\n",
    "            with open(file_path, \"r\") as infile:\n",
    "                try:\n",
    "                    data = json.load(infile)\n",
    "                    records.append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped broken file: {file_path} ({e})\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ Total judgments in metadata:\", len(df))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Print available columns\n",
    "print(\"üìÇ Columns in DataFrame:\", df.columns.tolist())\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show a sample row\n",
    "print(\"üîç Sample record:\")\n",
    "print(df.head(1).to_dict(orient=\"records\"))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Try accessing 'court' if it exists\n",
    "if \"court\" in df.columns:\n",
    "    print(\"‚öñÔ∏è Courts available:\", df[\"court_name\"].unique())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'court' column not found.\")\n",
    "    print(\"üëâ Available columns you can try instead:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9207f51-93f1-4446-8d3c-add5f166b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Path where metadata is stored\n",
    "metadata_dir = os.path.expanduser(\"~/high_court_dataset/metadata\")\n",
    "\n",
    "# Collect metadata records\n",
    "records = []\n",
    "for root, _, files in os.walk(metadata_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, f)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                try:\n",
    "                    data = json.load(infile)\n",
    "                    records.append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped broken file {file_path}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Total judgments in metadata:\", len(df))\n",
    "print(\"üìë Available columns:\", df.columns.tolist())\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show a sample row\n",
    "print(\"üîç Sample record:\")\n",
    "print(df.head(1).to_dict(orient=\"records\"))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use court_name instead of court\n",
    "if \"court_name\" in df.columns:\n",
    "    print(\"‚öñÔ∏è Courts available:\", df[\"court_name\"].unique())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No 'court_name' column found. Available:\", df.columns.tolist())\n",
    "\n",
    "# ---- Balanced Sampling ----\n",
    "if len(df) > 0:\n",
    "    target_total = 52000\n",
    "    courts = df[\"court_name\"].dropna().unique()\n",
    "    per_court = max(1, target_total // len(courts))\n",
    "    print(f\"üéØ Sampling about {per_court} judgments per court (total ~{target_total})\")\n",
    "\n",
    "    sampled = df.groupby(\"court_name\", group_keys=False).apply(\n",
    "        lambda g: g.sample(min(per_court, len(g)), random_state=42)\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Final sampled judgments:\", len(sampled))\n",
    "\n",
    "    # Save sampled list to CSV\n",
    "    out_csv = \"sampled_metadata.csv\"\n",
    "    sampled.to_csv(out_csv, index=False)\n",
    "    print(f\"üìÇ Saved sampled metadata list to: {out_csv}\")\n",
    "\n",
    "    # Also save just the file paths for easier downloading\n",
    "    if \"pdf_link\" in sampled.columns:\n",
    "        sampled[\"pdf_link\"].to_csv(\"sampled_paths.txt\", index=False, header=False)\n",
    "        print(\"üìÇ Saved file paths to: sampled_paths.txt\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No 'pdf_link' field found. Check available columns again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60787280-0481-4900-bc6a-1949342e30b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nyayaanumana)",
   "language": "python",
   "name": "nyayaanumana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
